---
layout: archive
title: "Projects"
permalink: /projects/
author_profile: true
classes: wide
---
I generally work on research related to machine learning, human computer interaction, and accessibility. 
My projects range from exploring the challenges of using a teachable object recognizer for people with and without visual impairments,
characterizing the interactions to identifying speech recognition errors with synthesized speech, and developing mobile/wearable devices.

## Teachable Interface for Personalizing an Object Recognizer

<!-- ![intro_image](/images/MachineTeachingPerception.png){:width="80%"}<br> -->
<!-- <img src='/images/MachineTeachingPerception.png' width=100%><br> -->
<p align="center">
  <img src="/images/MachineTeachingPerception.png" width="80%">
</p>

This project aims to build a teachable object recognizer (TOR) that helps people with visual impairments to identify objects independently using their smartphones. With a TOR, users can personalize the object recognizer by training the models with their own images. This project addresses two issues to develop this system: non-experts' perception of machine teaching, blind users' challenges of taking photos for training an object recognizer.

### Publications
[Crowdsourcing the Perception of Machine Teaching](/papers/CHI2020-CrowdTeaMa.pdf)<br>
**Jonggi Hong**, Kyungjun Lee, June Xu, Hernisa Kacorri<br>
Proc. SIGCHI Conference on Human Factors in Computing Systems (CHI 2020)

[Revisiting Blind Photography in the Context of Teachable Object Recognizers](/papers/ASSETS2019-Revisiting.pdf)<br>
Kyungjun Lee, **Jonggi Hong**, Ebrima Jarjue, Simone Pimento, Hernisa Kacorri <br>
Proc. International ACM SIGACCESS Conference on Computers and Accessibility (ASSETS 2019)


<hr style="height:2px;border-width:0;color:gray;background-color:gray">


## Identifying Speech Recognition Errors with Audio-only Interactions

<!-- ![intro_image](/images/dictation_CHI2017.png){:width="80%"}<br> -->
<!-- ![intro_image](/images/dictation_CHI2017.png){:class="img-responsive"}<br> -->
<p align="center">
  <img src="/images/dictation_CHI2017.png" width="80%">
</p>

While speech input has improved dramatically in the past few years, reviewing and editing the dictated text during non-visual use has been a challenge for people with visual impairments. This project characterizes the challenge of identifying ASR errors with audio-only interactions (i.e., listening to a synthesized speech).

### Publications
[Reviewing Speech Input with Audio: Differences between Blind and Sighted Users](/papers/TACCESS2020-speech.pdf)<br>
**Jonggi Hong**, Christine Vaing, Hernisa Kacorri, Leah Findlater<br>
ACM Transactions on Accessible Computing. 13, 1, Article 2 (TACCESS 2020)

[Identifying Speech Input Errors Through Audio-Only Interaction](/papers/CHI2018-DictationErrorsAudioOnly.pdf)<br>
**Jonggi Hong**, Leah Findlater<br>
Proc. SIGCHI Conference on Human Factors in Computing Systems (CHI 2018)


<hr style="height:2px;border-width:0;color:gray;background-color:gray">


## Interactions in Mobile and Wearable devices

<p align="center">
  <img src="/images/Haptic_GI2016.png" width="80%">
</p>
The wearable and mobile devices can enable novel interactions for people with disabilities. They can also enhance the interfaces of augmented reality applications and smart watches.

### Publications
[Evaluating Wrist-Based Haptic Feedback for Non-Visual Target Finding and Path Tracing on a 2D Surface](/papers/ASSETS2017-haptic.pdf)<br>
**Jonggi Hong**, Alisha Pradhan, Jon E. Froehlich, Leah Findlater<br>
Proc. International ACM SIGACCESS Conference on Computers and Accessibility (ASSETS 2017)

[The Cost of Turning Heads: A Comparison of a Head-Worn Display to a Smartphone for Supporting Persons With Aphasia in Conversation](/papers/ASSETS2016-AphasiaHMD.pdf)<br>
Kristin Williams, Karyn Moffatt, **Jonggi Hong**, Yasmeen Faroqi-Shah, Leah Findlater<br>
Proc. International ACM SIGACCESS Conference on Computers and Accessibility (ASSETS 2016)

[Evaluating Angular Accuracy of Wrist-based Haptic Directional Guidance for Hand Movement](/papers/GI2016-haptic.pdf)<br>
**Jonggi Hong**, Lee Stearns, Tony Cheng, Jon E. Froehlich, David Ross, Leah Findlater<br>
Proc. Graphics Interface Conference (GI 2016)

[SplitBoard: A Simple Split Soft Keyboard for Wristwatch-sized Touch Screens](/papers/CHI2015-SplitBoard.pdf)<br>
**Jonggi Hong**, Seongkook Heo, Poika Isokoski, Geehyuk Lee<br>
Proc. SIGCHI Conference on Human Factors in Computing Systems (CHI 2015)

[Smart Wristband: Touch-and-motionâ€“tracking Wearable Input Device for Smart Glasses](/papers/HCII2014-smartwristband.pdf)<br>
Jooyeun Ham, **Jonggi Hong**, Youngkyoon Jang, Seung Hwan Ko, Woontack Woo<br>
International Conference on Human-Computer Interaction (HCII 2014)